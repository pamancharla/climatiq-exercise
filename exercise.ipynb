{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two files attached containing the following data:\n",
    "\n",
    "- input-data.csv: details of 50 items from some user input.\n",
    "- activities.csv: a list of activities representing emission factors. Each activity is composed by a name (“activity_name” column), and is grouped by a set of categories (“category” column).\n",
    "\n",
    "Note: All additional information has been striped for simplicity, but for sake of completeness: these activities contain metadata about their respective emissions.\n",
    "\n",
    "Task: You are tasked with developing a system that finds the most relevant match for each of the input data strings from input-data.csv to activity names in activities.csv.\n",
    "\n",
    "Deliverable: Submit your solution as a Python script or a Jupyter notebook, including the following requirements:\n",
    "- Build a prototype model, including data processing, labeling and evaluation.\n",
    "- For each unstructured input record, return the best-matched activity (name and category) along with a score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_data_df = pd.read_csv(\"input-data.csv\")\n",
    "activities_df = pd.read_csv(\"activities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Shape: (49, 1)\n",
      "Activites Shape: (7133, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input Data Shape: {input_data_df.shape}\")\n",
    "print(f\"Activites Shape: {activities_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df = activities_df.drop_duplicates(subset=[\"activity_name\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activites Shape: (7133, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Activites Shape: {activities_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drill bits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Light bulb filaments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PACKAGING PALLET S7A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steel alloys for rails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hex bolt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Catalysts in chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t-joint, steel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aircraft structures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thermometers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Airplane fuselages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              item\n",
       "0                       Drill bits\n",
       "1             Light bulb filaments\n",
       "2             PACKAGING PALLET S7A\n",
       "3           Steel alloys for rails\n",
       "4                         hex bolt\n",
       "5  Catalysts in chemical reactions\n",
       "6                   t-joint, steel\n",
       "7              Aircraft structures\n",
       "8                     Thermometers\n",
       "9               Airplane fuselages"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gas condensing boiler 120-400kW (upright unit)</td>\n",
       "      <td>Electrical Equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spinach (market for spinach)</td>\n",
       "      <td>Arable Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potatoes crisps</td>\n",
       "      <td>Food/Beverages/Tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tax preparation services</td>\n",
       "      <td>Professional Services and Activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aluminium - North American</td>\n",
       "      <td>Metals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Savings institutions</td>\n",
       "      <td>Financial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hydrogen gaseous low pressure (market for hydr...</td>\n",
       "      <td>Fuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other commercial buildings</td>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aircraft</td>\n",
       "      <td>Vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>All other insurance related activities</td>\n",
       "      <td>Insurance Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       activity_name  \\\n",
       "0     Gas condensing boiler 120-400kW (upright unit)   \n",
       "1                       Spinach (market for spinach)   \n",
       "2                                    Potatoes crisps   \n",
       "3                           Tax preparation services   \n",
       "4                         Aluminium - North American   \n",
       "5                               Savings institutions   \n",
       "6  Hydrogen gaseous low pressure (market for hydr...   \n",
       "7                         Other commercial buildings   \n",
       "8                                           Aircraft   \n",
       "9             All other insurance related activities   \n",
       "\n",
       "                               category  \n",
       "0                  Electrical Equipment  \n",
       "1                        Arable Farming  \n",
       "2                Food/Beverages/Tobacco  \n",
       "3  Professional Services and Activities  \n",
       "4                                Metals  \n",
       "5                    Financial Services  \n",
       "6                                  Fuel  \n",
       "7                           Real Estate  \n",
       "8                              Vehicles  \n",
       "9                    Insurance Services  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 categories\n"
     ]
    }
   ],
   "source": [
    "num_categories = len(activities_df[\"category\"].unique())\n",
    "print(f\"{num_categories} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max category length: 820, Min category length: 1\n",
      "Median category length: 34.0\n",
      "Mean category length: 103.3768115942029\n"
     ]
    }
   ],
   "source": [
    "category_to_activity = {}\n",
    "category_lengths = []\n",
    "for category in activities_df[\"category\"].unique():\n",
    "    category_to_activity[category] = activities_df.index[activities_df[\"category\"] == category].to_list()\n",
    "    category_lengths.append(len(category_to_activity[category]))\n",
    "\n",
    "print(f\"Max category length: {max(category_lengths)}, Min category length: {min(category_lengths)}\")\n",
    "print(f\"Median category length: {pd.Series(category_lengths).median()}\")\n",
    "print(f\"Mean category length: {pd.Series(category_lengths).mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 Aluminium - not alloyed - bars / rods\n",
      "471 Iron non-alloy steel - bars / rods / long\n",
      "848 Steel - Wire rod\n",
      "1424 Iron non-alloy steel - bars rods hot-rolled drawn extruded forgings\n",
      "1520 Steel - hollow drill bars rods - forgings\n",
      "1864 Iron non-alloy steel - bars rods hot-rolled coils\n",
      "2311 Stainless steel - shapes sections bars rods long\n",
      "2761 Iron non-alloy steel - bars rods nec\n",
      "3845 Aluminium - alloys - bars / rods\n",
      "4140 Steel alloy - bars rods hot-rolled coils\n",
      "5459 Stainless steel - bars rods hot-rolled coils\n",
      "6026 Iron non-alloy steel - hot-rolled drawn extruded - bars rods long\n",
      "6084 Steel - hollow bars rods long\n"
     ]
    }
   ],
   "source": [
    "category = None\n",
    "activity_target = [\" rod\"]\n",
    "for index, row in activities_df.iterrows():\n",
    "    found_activity = True\n",
    "    if activity_target is not None:\n",
    "        found_activity = False\n",
    "        for t in activity_target:\n",
    "            if t in row[\"activity_name\"].lower():\n",
    "                found_activity = True\n",
    "                break\n",
    "    if found_activity and (category is None or row[\"category\"] in category):\n",
    "        print(index, row[\"activity_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity_name             Light bulbs\n",
       "category         Electrical Equipment\n",
       "Name: 6671, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities_df.iloc[6671]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following is in the format of:\n",
    "\"input item\": [(activity, score), (activity, score), ...]\n",
    "\n",
    "Items for which ground truth rankings were obtained:\n",
    "\"Control rods in nuclear ractors\": []\n",
    "\"\"\"\n",
    "\n",
    "test_set_relevant_mappings = {\n",
    "    13: [2930, 471, 2311],\n",
    "    27: [349, 770, 3745],\n",
    "    14: [3213, 4975],\n",
    "    45: [4277, 5433, 993],\n",
    "    38: [103, 1052],\n",
    "    10: [6946, 2635, 2307, 5035, 5537],\n",
    "    36: [25, 3044, 5329, 5484, 6765],\n",
    "    1: [3501, 6671],\n",
    "    42: [467],\n",
    "    24: [5807]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def average_precision_at_k(predicted_indices: List[int], relevant_indices: List[int], k: int) -> float:\n",
    "    num_relevant = 0\n",
    "    sum_precision_at_k = 0\n",
    "    for i, index in enumerate(predicted_indices):\n",
    "        if index in relevant_indices:\n",
    "            num_relevant += 1\n",
    "            sum_precision_at_k += num_relevant / (i + 1) # add precision at k\n",
    "        if i + 1 >= k:\n",
    "            break\n",
    "    return sum_precision_at_k / min(k, len(relevant_indices))\n",
    "\n",
    "\n",
    "def mean_average_precision_at_k(\n",
    "        item_to_predicted_indices: Dict[int, List[List[int]]],\n",
    "        test_set_relevant_mappings: Dict[int, List[List[int]]],\n",
    "        k: int\n",
    ") -> float:\n",
    "    sum_average_precision_at_k = 0\n",
    "    for item_index, predicted_indices in item_to_predicted_indices.items():\n",
    "        sum_average_precision_at_k += average_precision_at_k(predicted_indices, test_set_relevant_mappings[item_index], k)\n",
    "    return sum_average_precision_at_k / len(item_to_predicted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_closest_matches(query_embedding: List[float], target_embeddings: List[List[float]], k: int = 5) -> List[int]:\n",
    "    similarities = cosine_similarity([query_embedding], target_embeddings)\n",
    "    return np.argsort(similarities)[0][-5:][::-1]\n",
    "\n",
    "\n",
    "def get_test_set_performance(\n",
    "        query_embeddings: List[List[float]],\n",
    "        target_embeddings: List[List[float]],\n",
    "        test_set_relevant_mappings: Dict[int, List[int]],\n",
    "        k: List[int]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Given the predicted query and target embeddings, return the mean average precision at all k values\n",
    "    provided.\n",
    "    \"\"\"\n",
    "    item_to_predicted_activity_indices = {}\n",
    "    for test_index in test_set_relevant_mappings:\n",
    "        test_embedding = query_embeddings[test_index]\n",
    "        closest_matches = get_closest_matches(test_embedding, target_embeddings)\n",
    "        item_to_predicted_activity_indices[test_index] = closest_matches\n",
    "\n",
    "    map_at_k = []\n",
    "    for k_val in k:\n",
    "        map_at_k.append(mean_average_precision_at_k(item_to_predicted_activity_indices, test_set_relevant_mappings, k_val))\n",
    "    return map_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df[\"combined_string\"] = activities_df.apply(lambda x: x[\"category\"] + \": \" + x[\"activity_name\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@1: 0.3, MAP@5: 0.22333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert text to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words=\"english\") # Use bigrams on top of single words\n",
    "query_embeddings = vectorizer.fit_transform(input_data_df[\"item\"].tolist()).toarray()\n",
    "target_embeddings = vectorizer.transform(activities_df[\"combined_string\"].tolist())\n",
    "map_at_k = get_test_set_performance(query_embeddings, target_embeddings, test_set_relevant_mappings, [1, 5])\n",
    "print(f\"MAP@1: {map_at_k[0]}, MAP@5: {map_at_k[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Sentence Transformer Model Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preetamamancharla/.pyenv/versions/3.11.5/envs/climatiq-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@1: 0.4, MAP@5: 0.29833333333333334\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "mini_lm_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "target_embeddings = mini_lm_model.encode(activities_df[\"combined_string\"].tolist())\n",
    "query_embeddings = mini_lm_model.encode(input_data_df[\"item\"].tolist())\n",
    "\n",
    "map_at_k = get_test_set_performance(query_embeddings, target_embeddings, test_set_relevant_mappings, [1, 5])\n",
    "print(f\"MAP@1: {map_at_k[0]}, MAP@5: {map_at_k[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intfloat/e5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@1: 0.5, MAP@5: 0.37416666666666665\n"
     ]
    }
   ],
   "source": [
    "infloat_model = SentenceTransformer(\"intfloat/e5-base\")\n",
    "target_embeddings = infloat_model.encode(activities_df[\"combined_string\"].tolist())\n",
    "query_embeddings = infloat_model.encode(input_data_df[\"item\"].tolist())\n",
    "\n",
    "map_at_k = get_test_set_performance(query_embeddings, target_embeddings, test_set_relevant_mappings, [1, 5])\n",
    "print(f\"MAP@1: {map_at_k[0]}, MAP@5: {map_at_k[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@1: 0.4, MAP@5: 0.2833333333333333\n"
     ]
    }
   ],
   "source": [
    "mpnet_base_model = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\")\n",
    "target_embeddings = mpnet_base_model.encode(activities_df[\"combined_string\"].tolist())\n",
    "query_embeddings = mpnet_base_model.encode(input_data_df[\"item\"].tolist())\n",
    "\n",
    "map_at_k = get_test_set_performance(query_embeddings, target_embeddings, test_set_relevant_mappings, [1, 5])\n",
    "print(f\"MAP@1: {map_at_k[0]}, MAP@5: {map_at_k[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use intfloat/e5-base for final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "infloat_model = SentenceTransformer(\"intfloat/e5-base\")\n",
    "target_embeddings = infloat_model.encode(activities_df[\"combined_string\"].tolist())\n",
    "query_embeddings = infloat_model.encode(input_data_df[\"item\"].tolist())\n",
    "\n",
    "output_activity = []\n",
    "output_category = []\n",
    "output_scores = []\n",
    "for query_embedding in query_embeddings:\n",
    "    similarities = cosine_similarity([query_embedding], target_embeddings)\n",
    "    best_match_index = np.argmax(similarities)\n",
    "    output_activity.append(activities_df.iloc[best_match_index][\"activity_name\"])\n",
    "    output_category.append(activities_df.iloc[best_match_index][\"category\"])\n",
    "    output_scores.append(similarities[0][best_match_index])\n",
    "\n",
    "output_df = pd.DataFrame({\n",
    "    \"item\": input_data_df[\"item\"],\n",
    "    \"activity\": output_activity,\n",
    "    \"category\": output_category,\n",
    "    \"score\": output_scores\n",
    "})\n",
    "output_df.to_csv(\"output-data.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatiq-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
